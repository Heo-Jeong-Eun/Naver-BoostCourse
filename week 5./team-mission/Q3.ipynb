{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Q3. MNIST 데이터셋을 Load -> 학습할 모델을 구현, 가중치 초기화 \n",
    "#     -> 구현한 모델을 학습시키기 위한 loss 함수 opitmizer 구현\n",
    "# output : loss 함수, opitmizer 구현\n",
    "\n",
    "# A. \n",
    "#   1. device = GPU를 사용 가능하면 cuda, 아닌 경우는 cpu\n",
    "#   2. linear = 학습시키기 위한 모델 정의\n",
    "#   3. 가중치 초기화 \n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision.datasets as dset \n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "linear = torch.nn.Linear(784, 10, bias = True).to(device)\n",
    "\n",
    "torch.nn.init.normal_(linear.weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = torch.nn.CrossEntropyLoss().to(device)\n",
    "# 다중분류를 위한 손실함수, 다중 분류에 사용된다. \n",
    "# torch.nn.CrossEntropyLoss는 nnLogSoftMax와 nn.NLLLoss 연산의 조합이다. \n",
    "# 배치 처리에 대한 손실값은 배치를 구성하는 각 데이터 손실값의 평균이다. \n",
    "# 연산을 한번에 처리해 수식이 간소화 되어 역전파가 더 안정적으로 이루어지므로 위 코드와 같은 방법이 실제 사용에 권장된다.\n",
    "# Softmax와 Log처리 및 CrossEntropy연산의 조합이다. \n",
    "optimizer = torch.optim.SGD(linear.parameters(), lr = 0.1)\n",
    "# parameter 최적화\n",
    "# 최적화는 각 학습 단계에서 모델의 오류를 줄이기위해 모델 매개변수를 조정하는 과정이다. \n",
    "# 최적화 알고리즘은 이 과정에서 수행되는 방식을 정의한다. \n",
    "# 위 코드의 경우 Stochastic Gradient Descent, 즉 확률적 경사하강법을 정의한다.\n",
    "# 학습하려는 모델의 매개변수와 학습률을 하이퍼파라미터를 등록해 optimizer를 초기화한다.\n",
    "# optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
